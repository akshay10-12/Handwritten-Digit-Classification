{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks for Handwritten Digit Recognition, Multiclass \n",
    "\n",
    "In this notebook, we will use a neural network to recognize the hand-written digits 0-9.\n",
    "\n",
    "\n",
    "# Outline\n",
    "- [ 1 - Packages ](#1)\n",
    "- [ 2 - ReLU Activation](#2)\n",
    "- [ 3 - Softmax Function](#3)\n",
    "- [ 4 - Neural Networks](#4)\n",
    "  - [ 4.1 Problem Statement](#4.1)\n",
    "  - [ 4.2 Dataset](#4.2)\n",
    "  - [ 4.3 Model representation](#4.3)\n",
    "  - [ 4.4 Tensorflow Model Implementation](#4.4)\n",
    "  - [ 4.5 Softmax placement](#4.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"1\"></a>\n",
    "## 1 - Packages \n",
    "\n",
    "First, let's run the cell below to import all the packages that we will need.\n",
    "- [numpy](https://numpy.org/) is the fundamental package for scientific computing with Python.\n",
    "- [matplotlib](http://matplotlib.org) is a popular library to plot graphs in Python.\n",
    "- [tensorflow](https://www.tensorflow.org/) a popular platform for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.activations import linear, relu, sigmoid\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('./deeplearning.mplstyle')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "tf.autograph.set_verbosity(0)\n",
    "\n",
    "from public_tests import * \n",
    "\n",
    "from autils import *\n",
    "from lab_utils_softmax import plt_softmax\n",
    "np.set_printoptions(precision=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"2\"></a>\n",
    "## 2 - ReLU Activation\n",
    "The Rectified Linear Unit (ReLU) activation function is given by -  \n",
    "$$ a = max(0,z) \\quad\\quad\\text {# ReLU function} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"3\"></a>\n",
    "## 3 - Softmax Function\n",
    "A multiclass neural network generates N outputs. One output is selected as the predicted answer. In the output layer, a vector $\\mathbf{z}$ is generated by a linear function which is fed into a softmax function. The softmax function converts $\\mathbf{z}$  into a probability distribution as described below. After applying softmax, each output will be between 0 and 1 and the outputs will sum to 1. They can be interpreted as probabilities. The larger inputs to the softmax will correspond to larger output probabilities.\n",
    "<center>  <img  src=\"./images/C2_W2_NNSoftmax.PNG\" width=\"600\" />  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The softmax function can be written:\n",
    "$$a_j = \\frac{e^{z_j}}{ \\sum_{k=0}^{N-1}{e^{z_k} }} \\tag{1}$$\n",
    "\n",
    "Where $z = \\mathbf{w} \\cdot \\mathbf{x} + b$ and N is the number of feature/categories in the output layer.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Numpy implementation of Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softmax(z):\n",
    "    ez = np.exp(z)\n",
    "    summ = np.sum(ez)\n",
    "    a = ez/summ\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_softmax(z):         [0.03 0.09 0.24 0.64]\n",
      "tensorflow softmax(z): [0.03 0.09 0.24 0.64]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "z = np.array([1., 2., 3., 4.])\n",
    "a = my_softmax(z)\n",
    "atf = tf.nn.softmax(z)\n",
    "print(f\"my_softmax(z):         {a}\")\n",
    "print(f\"tensorflow softmax(z): {atf}\")\n",
    "\n",
    "# BEGIN UNIT TEST  \n",
    "test_my_softmax(my_softmax)\n",
    "# END UNIT TEST  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<a name=\"4\"></a>\n",
    "## 4 - Neural Networks\n",
    "\n",
    "In the previous notebook, we implemented a neural network to do binary classification. Here, we will extend that to multiclass classification. This will utilize the softmax activation.\n",
    "\n",
    "\n",
    "<a name=\"4.1\"></a>\n",
    "### 4.1 Problem Statement\n",
    "\n",
    "Now, we will use a neural network to recognize ten handwritten digits, 0-9. This is a multiclass classification task where one of n choices is selected. Automated handwritten digit recognition is widely used today - from recognizing zip codes (postal codes) on mail envelopes to recognizing amounts written on bank checks. \n",
    "\n",
    "\n",
    "<a name=\"4.2\"></a>\n",
    "### 4.2 Dataset\n",
    "\n",
    "We begin by loading the dataset for this task. \n",
    "- The `load_data()` function shown below loads the data into variables `X` and `y`\n",
    "\n",
    "\n",
    "- The data set contains 5000 training examples of handwritten digits $^1$.  \n",
    "\n",
    "    - Each training example is a 20-pixel x 20-pixel grayscale image of the digit. \n",
    "        - Each pixel is represented by a floating-point number indicating the grayscale intensity at that location. \n",
    "        - The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector. \n",
    "        - Each training examples becomes a single row in our data matrix `X`. \n",
    "        - This gives us a 5000 x 400 matrix `X` where every row is a training example of a handwritten digit image.\n",
    "\n",
    "$$X = \n",
    "\\left(\\begin{array}{cc} \n",
    "--- (x^{(1)}) --- \\\\\n",
    "--- (x^{(2)}) --- \\\\\n",
    "\\vdots \\\\ \n",
    "--- (x^{(m)}) --- \n",
    "\\end{array}\\right)$$ \n",
    "\n",
    "- The second part of the training set is a 5000 x 1 dimensional vector `y` that contains labels for the training set\n",
    "    - `y = 0` if the image is of the digit `0`, `y = 4` if the image is of the digit `4` and so on.\n",
    "\n",
    "$^1$<sub> This is a subset of the MNIST handwritten digit dataset (http://yann.lecun.com/exdb/mnist/)</sub>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "X, y = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 View the variables\n",
    "- A good place to start is to print out each variable and see what it contains.\n",
    "\n",
    "The code below prints the first element in the variables `X` and `y`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of X is:  [ 0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  8.56e-06  1.94e-06 -7.37e-04\n",
      " -8.13e-03 -1.86e-02 -1.87e-02 -1.88e-02 -1.91e-02 -1.64e-02 -3.78e-03\n",
      "  3.30e-04  1.28e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  1.16e-04  1.20e-04 -1.40e-02 -2.85e-02  8.04e-02\n",
      "  2.67e-01  2.74e-01  2.79e-01  2.74e-01  2.25e-01  2.78e-02 -7.06e-03\n",
      "  2.35e-04  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  1.28e-17 -3.26e-04 -1.39e-02  8.16e-02  3.83e-01  8.58e-01  1.00e+00\n",
      "  9.70e-01  9.31e-01  1.00e+00  9.64e-01  4.49e-01 -5.60e-03 -3.78e-03\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  5.11e-06  4.36e-04 -3.96e-03\n",
      " -2.69e-02  1.01e-01  6.42e-01  1.03e+00  8.51e-01  5.43e-01  3.43e-01\n",
      "  2.69e-01  6.68e-01  1.01e+00  9.04e-01  1.04e-01 -1.66e-02  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  2.60e-05 -3.11e-03  7.52e-03  1.78e-01\n",
      "  7.93e-01  9.66e-01  4.63e-01  6.92e-02 -3.64e-03 -4.12e-02 -5.02e-02\n",
      "  1.56e-01  9.02e-01  1.05e+00  1.51e-01 -2.16e-02  0.00e+00  0.00e+00\n",
      "  0.00e+00  5.87e-05 -6.41e-04 -3.23e-02  2.78e-01  9.37e-01  1.04e+00\n",
      "  5.98e-01 -3.59e-03 -2.17e-02 -4.81e-03  6.17e-05 -1.24e-02  1.55e-01\n",
      "  9.15e-01  9.20e-01  1.09e-01 -1.71e-02  0.00e+00  0.00e+00  1.56e-04\n",
      " -4.28e-04 -2.51e-02  1.31e-01  7.82e-01  1.03e+00  7.57e-01  2.85e-01\n",
      "  4.87e-03 -3.19e-03  0.00e+00  8.36e-04 -3.71e-02  4.53e-01  1.03e+00\n",
      "  5.39e-01 -2.44e-03 -4.80e-03  0.00e+00  0.00e+00 -7.04e-04 -1.27e-02\n",
      "  1.62e-01  7.80e-01  1.04e+00  8.04e-01  1.61e-01 -1.38e-02  2.15e-03\n",
      " -2.13e-04  2.04e-04 -6.86e-03  4.32e-04  7.21e-01  8.48e-01  1.51e-01\n",
      " -2.28e-02  1.99e-04  0.00e+00  0.00e+00 -9.40e-03  3.75e-02  6.94e-01\n",
      "  1.03e+00  1.02e+00  8.80e-01  3.92e-01 -1.74e-02 -1.20e-04  5.55e-05\n",
      " -2.24e-03 -2.76e-02  3.69e-01  9.36e-01  4.59e-01 -4.25e-02  1.17e-03\n",
      "  1.89e-05  0.00e+00  0.00e+00 -1.94e-02  1.30e-01  9.80e-01  9.42e-01\n",
      "  7.75e-01  8.74e-01  2.13e-01 -1.72e-02  0.00e+00  1.10e-03 -2.62e-02\n",
      "  1.23e-01  8.31e-01  7.27e-01  5.24e-02 -6.19e-03  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00 -9.37e-03  3.68e-02  6.99e-01  1.00e+00  6.06e-01\n",
      "  3.27e-01 -3.22e-02 -4.83e-02 -4.34e-02 -5.75e-02  9.56e-02  7.27e-01\n",
      "  6.95e-01  1.47e-01 -1.20e-02 -3.03e-04  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00 -6.77e-04 -6.51e-03  1.17e-01  4.22e-01  9.93e-01  8.82e-01\n",
      "  7.46e-01  7.24e-01  7.23e-01  7.20e-01  8.45e-01  8.32e-01  6.89e-02\n",
      " -2.78e-02  3.59e-04  7.15e-05  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  1.53e-04  3.17e-04 -2.29e-02 -4.14e-03  3.87e-01  5.05e-01  7.75e-01\n",
      "  9.90e-01  1.01e+00  1.01e+00  7.38e-01  2.15e-01 -2.70e-02  1.33e-03\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  2.36e-04 -2.26e-03 -2.52e-02 -3.74e-02  6.62e-02  2.91e-01\n",
      "  3.23e-01  3.06e-01  8.76e-02 -2.51e-02  2.37e-04  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  6.21e-18  6.73e-04 -1.13e-02 -3.55e-02 -3.88e-02\n",
      " -3.71e-02 -1.34e-02  9.91e-04  4.89e-05  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00  0.00e+00\n",
      "  0.00e+00]\n"
     ]
    }
   ],
   "source": [
    "print ('The first element of X is: ', X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first element of y is:  0\n",
      "The last element of y is:  9\n"
     ]
    }
   ],
   "source": [
    "print ('The first element of y is: ', y[0,0])\n",
    "print ('The last element of y is: ', y[-1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Check the dimensions of the variables\n",
    "\n",
    "Another way to get familiar with the data is to view its dimensions. We print the shape of X and y and also the number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (5000, 400)\n",
      "The shape of y is: (5000, 1)\n",
      "The number of training examples is: 5000\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of y is: ' + str(y.shape))\n",
    "print('The number of training examples is: ' + str(len(X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.3 Visualizing the Data\n",
    "We will now visualize a subset of the training set. \n",
    "- In the cell below, the code randomly selects 64 rows from `X`, maps each row back to a 20 pixel by 20 pixel grayscale image and displays the images together. \n",
    "- The label for each image is displayed above the image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action = 'ignore', category = FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3e14f3444bf4efc8dcac5e0da2b96a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8 , figsize = (6,6))\n",
    "fig.tight_layout(pad = 0.13, rect = [0, 0.03, 1, 0.91]) #left, bottom, right, top\n",
    "\n",
    "widgvis(fig)\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    #Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    #Select rows corresponding to these random indices and reshape the image\n",
    "    X_random = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    #Display the image\n",
    "    ax.imshow(X_random, cmap = 'gray')\n",
    "    \n",
    "    #Display the label above the image\n",
    "    ax.set_title(y[random_index, 0])\n",
    "    ax.set_axis_off()\n",
    "    fig.suptitle(\"Label, image\", fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.3\"></a>\n",
    "### 4.3 Model representation\n",
    "\n",
    "The neural network we will use in this notebook is shown in the figure below. \n",
    "- This has two dense layers with ReLU activations followed by an output layer with a linear activation. \n",
    "    - Recall that our inputs are pixel values of digit images.\n",
    "    - Since the images are of size $20\\times20$, this gives us $400$ inputs  \n",
    "    \n",
    "<img src=\"images/C2_W2_Assigment_NN.png\" width=\"600\" height=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The parameters have dimensions that are sized for a neural network with $25$ units in layer 1, $15$ units in layer 2 and $10$ output units in layer 3, one for each digit.\n",
    "\n",
    "    - Recall that the dimensions of these parameters is determined as follows:\n",
    "        - If network has $s_{in}$ units in a layer and $s_{out}$ units in the next layer, then \n",
    "            - $W$ will be of dimension $s_{in} \\times s_{out}$.\n",
    "            - $b$ will be a vector with $s_{out}$ elements\n",
    "  \n",
    "    - Therefore, the shapes of `W`, and `b`,  are \n",
    "        - layer1: The shape of `W1` is (400, 25) and the shape of `b1` is (25,)\n",
    "        - layer2: The shape of `W2` is (25, 15) and the shape of `b2` is: (15,)\n",
    "        - layer3: The shape of `W3` is (15, 10) and the shape of `b3` is: (10,)\n",
    "               "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"4.5\"></a>\n",
    "### 4.5 Softmax placement\n",
    "Numerical stability is improved if the softmax is grouped with the loss function rather than the output layer during training. This has implications when *building* the model and *using* the model.  \n",
    "Building:  \n",
    "* The final Dense layer should use a 'linear' activation. This is effectively no activation. \n",
    "* The `model.compile` statement will indicate this by including `from_logits=True`.\n",
    "`loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True) `  \n",
    "* This does not impact the form of the target. In the case of SparseCategorialCrossentropy, the target is the expected digit, 0-9.\n",
    "\n",
    "Using the model:\n",
    "* The outputs are not probabilities. If output probabilities are desired, apply a softmax function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234) #for consistent results\n",
    "model = Sequential(\n",
    "    [ \n",
    "       tf.keras.Input(shape = (400,)),\n",
    "       Dense(units =25, activation = 'relu', name = 'L1'),\n",
    "       Dense(units = 15, activation = 'relu', name = 'L2'),\n",
    "       Dense(units = 10, activation = 'linear', name = 'L3')  \n",
    "    ], name = 'my_model'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " L1 (Dense)                  (None, 25)                10025     \n",
      "                                                                 \n",
      " L2 (Dense)                  (None, 15)                390       \n",
      "                                                                 \n",
      " L3 (Dense)                  (None, 10)                160       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,575\n",
      "Trainable params: 10,575\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter counts shown in the summary correspond to the number of elements in the weight and bias arrays as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's further examine the weights to verify that tensorflow produced the same dimensions as we calculated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "[layer1, layer2, layer3] = model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 shape = (400, 25), b1 shape = (25,)\n",
      "W2 shape = (25, 15), b2 shape = (15,)\n",
      "W3 shape = (15, 10), b3 shape = (10,)\n"
     ]
    }
   ],
   "source": [
    "#### Examine Weights shapes\n",
    "W1,b1 = layer1.get_weights()\n",
    "W2,b2 = layer2.get_weights()\n",
    "W3,b3 = layer3.get_weights()\n",
    "print(f\"W1 shape = {W1.shape}, b1 shape = {b1.shape}\")\n",
    "print(f\"W2 shape = {W2.shape}, b2 shape = {b2.shape}\")\n",
    "print(f\"W3 shape = {W3.shape}, b3 shape = {b3.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code:\n",
    "* defines a loss function, `SparseCategoricalCrossentropy` and indicates the softmax should be included with the  loss calculation by adding `from_logits=True`)\n",
    "* defines an optimizer. A popular choice is Adaptive Moment (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "157/157 [==============================] - 1s 2ms/step - loss: 1.7094\n",
      "Epoch 2/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.7480\n",
      "Epoch 3/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.4428\n",
      "Epoch 4/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.3463\n",
      "Epoch 5/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2977\n",
      "Epoch 6/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2630\n",
      "Epoch 7/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2361\n",
      "Epoch 8/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2131\n",
      "Epoch 9/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.2004\n",
      "Epoch 10/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1805\n",
      "Epoch 11/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1692\n",
      "Epoch 12/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1580\n",
      "Epoch 13/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1507\n",
      "Epoch 14/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1396\n",
      "Epoch 15/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1289\n",
      "Epoch 16/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1255\n",
      "Epoch 17/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1154\n",
      "Epoch 18/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1102\n",
      "Epoch 19/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1016\n",
      "Epoch 20/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0970\n",
      "Epoch 21/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0926\n",
      "Epoch 22/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0891\n",
      "Epoch 23/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0828\n",
      "Epoch 24/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0785\n",
      "Epoch 25/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0755\n",
      "Epoch 26/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0713\n",
      "Epoch 27/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0701\n",
      "Epoch 28/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0617\n",
      "Epoch 29/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0578\n",
      "Epoch 30/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0550\n",
      "Epoch 31/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0511\n",
      "Epoch 32/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0499\n",
      "Epoch 33/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0462\n",
      "Epoch 34/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0437\n",
      "Epoch 35/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0422\n",
      "Epoch 36/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0396\n",
      "Epoch 37/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0366\n",
      "Epoch 38/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0344\n",
      "Epoch 39/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0312\n",
      "Epoch 40/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0294\n",
      "Epoch 41/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0272\n",
      "Epoch 42/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0266\n",
      "Epoch 43/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0251\n",
      "Epoch 44/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0218\n",
      "Epoch 45/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0221\n",
      "Epoch 46/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0207\n",
      "Epoch 47/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0223\n",
      "Epoch 48/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0186\n",
      "Epoch 49/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0165\n",
      "Epoch 50/50\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.0149\n"
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X,y,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction \n",
    "To make a prediction, use Keras `predict`. Below, X[1015] contains an image of a two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9af0accf744c92b0c3ee9c11951794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicting a Two: \n",
      "[[-19.58 -19.62  15.65  -4.83 -25.77 -12.11 -13.08  -9.18  -6.27 -20.69]]\n",
      " Largest Prediction index: 2\n"
     ]
    }
   ],
   "source": [
    "image_of_two = X[1124]\n",
    "display_digit(image_of_two)\n",
    "\n",
    "prediction = model.predict(image_of_two.reshape(1,400))  # prediction\n",
    "\n",
    "print(f\" predicting a Two: \\n{prediction}\")\n",
    "print(f\" Largest Prediction index: {np.argmax(prediction)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The largest output is prediction[2], indicating the predicted digit is a '2'. If the problem only requires a selection, that is sufficient. Use NumPy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) to select it. If the problem requires a probability, a softmax is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " predicting a Two. Probability vector: \n",
      "[[5.04e-16 4.82e-16 1.00e+00 1.28e-09 1.03e-18 8.79e-13 3.36e-13 1.65e-11\n",
      "  3.02e-10 1.66e-16]]\n",
      "Total of predictions: 1.000\n"
     ]
    }
   ],
   "source": [
    "prediction_p = tf.nn.softmax(prediction)\n",
    "\n",
    "print(f\" predicting a Two. Probability vector: \\n{prediction_p}\")\n",
    "print(f\"Total of predictions: {np.sum(prediction_p):0.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return an integer representing the predicted target, we want the index of the largest probability. This is accomplished with the Numpy [argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "np.argmax(prediction_p): 2\n"
     ]
    }
   ],
   "source": [
    "yhat = np.argmax(prediction_p)\n",
    "\n",
    "print(f\"np.argmax(prediction_p): {yhat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare the predictions vs the labels for a random sample of 64 digits. This takes a moment to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "717bfb3c4f394a94ba17a2aa9bad42ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m, n = X.shape\n",
    "\n",
    "fig, axes = plt.subplots(8,8, figsize=(5,5))\n",
    "fig.tight_layout(pad=0.13,rect=[0, 0.03, 1, 0.91]) #[left, bottom, right, top]\n",
    "widgvis(fig)\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    # Select random indices\n",
    "    random_index = np.random.randint(m)\n",
    "    \n",
    "    # Select rows corresponding to the random indices and\n",
    "    # reshape the image\n",
    "    X_random = X[random_index].reshape((20,20)).T\n",
    "    \n",
    "    # Display the image\n",
    "    ax.imshow(X_random, cmap='gray')\n",
    "    \n",
    "    # Predict using the Neural Network\n",
    "    prediction = model.predict(X[random_index].reshape(1,400))\n",
    "    prediction_p = tf.nn.softmax(prediction)\n",
    "    yhat = np.argmax(prediction_p)\n",
    "    \n",
    "    # Display the label above the image\n",
    "    ax.set_title(f\"{y[random_index,0]},{yhat}\",fontsize=10)\n",
    "    ax.set_axis_off()\n",
    "fig.suptitle(\"Label, yhat\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the errors. \n",
    ">Note: increasing the number of training epochs can eliminate the errors on this data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4290472b69cd48bca3e4fa45ce0dc2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 errors out of 5000 images\n"
     ]
    }
   ],
   "source": [
    "print( f\"{display_errors(model,X,y)} errors out of {len(X)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "dl_toc_settings": {
   "rndtag": "89367"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
